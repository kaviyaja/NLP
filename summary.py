# -*- coding: utf-8 -*-
"""Summary.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hCUkrJlYcZvKvmhUcOrdSE1x8WR2-5yx
"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

# 1. Load a T5 model for summarization
model_name = "t5-small"  # or "google/mt5-small" for multilingual
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# 2. Create a summarization pipeline
summarizer = pipeline("summarization", model=model, tokenizer=tokenizer)

# 3. Provide the input text (news article, report...)
text = """
The Text-to-Text Transfer Transformer (T5) is a model by Google that treats every NLP task
as a text-to-text problem. You prefix the task (e.g., "summarize:") to the input and feed
it into T5, which then outputs the result text. It's useful for translation, summarization,
question answering, and more.
"""

# 4. Generate a summary
summary = summarizer(text, max_length=60, min_length=20, do_sample=False)[0]['summary_text']
print(" Summary:", summary)